# OLLAMA_LOCAL
Experiment with LLM with Python

I want to create a complex Software but i try to implement all part in folders.
Note discretion : Below i say 'click' but in my case i refer to use motion hand with my webcam for implement better the software.

[ Folder- LAYOUT ]
- Software need to have this type of layout for a good User experience

[ FOLDER - DIPENDENCY ]  
- When the Software it's complete here is the base script for make a pool of python and folder as well.

[ Simple SOFTWARE TUI WITH OLLAMA]
- This folder it is a implement a simple AI local using Ollama tools for implement all software.

[ ??? - How it's works the software?  - ???]
- THe first time you have few option for input data ( text/audio/video/webcam2/USB custom/Cloud )


|  _A_ | _B_ | _C_|
| ------ | --- | --- |

|    _INPUT_D_   |
| ------ |

Naming of layout : 
- Section ' _A_ ' has a  [ Data Generate from _INPUT_] 
  - ALL data need to check manually
- Section ' _B_ ' it's your document
- Section ' _C_ ' it's for detail of that particular selection



Example of User EXperience : 

[Phase 1 create DATA ]
#1 In your screen you don't have nothing it will be create a pool of data.
#2 Input your data here in a section D, for example "tell me how many color we have" ... 
example of output -> ( red, orange, yellow, chartreuse green, green, spring green, cyan, light blue, blue, purple, magenta, and pink )
This tupla of color will be "upload" in to section A.
Repeat till you have all your data.  (text image video etc...)

[ Phase 2 MANAGE YOUR DATA ]

Now you can Drag&Drop your entry in _B_ section. 
- Number(s)
  --INT
  --FLOAT
- Letter(s)
  --Word(s)
  --phrase
- Image(s)
- Video etc... )

[ Details  of your data]
When Click or Drag&Drop this part it's will be enable open and show some details like
- Show the Reference location ?  Book  / Video / DATABASE 
- Show Metadata [ Will help you in LLM ]
